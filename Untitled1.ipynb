{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af68c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "#import Ipython.display as ipd\n",
    "#from Ipython import display as ipd\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "\n",
    "import IPython\n",
    "\n",
    "from IPython.display import Audio\n",
    "\n",
    "# sphinx_gallery_thumbnail_path = '_static/playback-thumbnail.png'\n",
    "\n",
    "# We'll need IPython.display's Audio widget\n",
    "from IPython.display import Audio\n",
    "\n",
    "# We'll also use `mir_eval` to synthesize a signal for us\n",
    "import mir_eval.sonify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce177b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data, sample_rate= librosa.load('UrbanSound8K/audio/fold1/7383-3-0-0.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bfd37b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'UrbanSound8K/audio/fold1/24074-1-0-10.wav'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d04fbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (15,5))\n",
    "\n",
    "librosa.display.waveshow(data, sr = sample_rate)\n",
    "Audio(filename);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f36a6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f051def2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import wavfile as wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24067bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_sample_rate, scipy_audio = wav.read(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2fe546",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1355a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_audio\n",
    "\n",
    "# integer values for each point of the sound wave\n",
    "\n",
    "#shows two channel audio and not normalized when load with SciPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff594d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "scipy_audio.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b7a1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(scipy_audio);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac9bec2",
   "metadata": {},
   "source": [
    "see that Librosa normalizes the sample rate to 22050, if use SciPy to load in the file, take the sample rate at it's regular rate, here 44100 Hz.\n",
    "\n",
    "Librosa also puts the audio file into \"Mono\" rather than \"Stereo\" to be only one channel of audio data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9350f506",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856fcdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543ea7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data = pd.read_csv('UrbanSound8K/metadata/UrbanSound8K.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56dd1430",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab076aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "for Row, \n",
    "\n",
    "os.shutil.copy2('/Users/eitan/Documents/Flatiron/Capstone/UrbanSound8K/audio/fold{}/{}'\\\n",
    ".format(Row['fold']/Row['slice_file_name']), /Users/eitan/Documents/Flatiron/Capstone/Data\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f90a638f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_data['class'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098f8b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename_2 = 'UrbanSound8K/audio/fold5/100263-2-0-137.wav'\n",
    "data_2, sample_rate_2= librosa.load(filename_2)\n",
    "\n",
    "Audio(filename_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8983ecb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c0be0b1d",
   "metadata": {},
   "source": [
    "### Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25959be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "auio_file_path = 'UrbanSound8K/audio/fold5/100263-2-0-137.wav'\n",
    "audio_data, samp_rate = librosa.load(auio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "162b1171",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(audio_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "852e5801",
   "metadata": {},
   "outputs": [],
   "source": [
    "wav_samp_rate, wave_audio = wav.read(auio_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd73f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "wave_audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab40f02c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12,5))\n",
    "plt.plot(wave_audio);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1424c8f5",
   "metadata": {},
   "source": [
    "mel-frequency cepstral coefficients (MFCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7294f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs = librosa.feature.mfcc(y = audio_data, sr = samp_rate, n_mfcc = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16215818",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfccs.shape\n",
    "\n",
    "# audio signal patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52fcd33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplot_mosaic(\"hSSS;hSSS;hSSS;.vvv\")\n",
    "y, sr = librosa.load(librosa.ex('trumpet'))\n",
    "chroma = librosa.feature.chroma_cqt(y=y, sr=sr)\n",
    "sim = librosa.segment.recurrence_matrix(chroma, mode='affinity')\n",
    "librosa.display.specshow(sim, ax=ax['S'], sr=sr,\n",
    "                         x_axis='time', y_axis='time',\n",
    "                         auto_aspect=False)\n",
    "ax['S'].label_outer()\n",
    "ax['S'].sharex(ax['v'])\n",
    "ax['S'].sharey(ax['h'])\n",
    "ax['S'].set(title='Self-similarity')\n",
    "librosa.display.waveshow(y, ax=ax['v'])\n",
    "ax['v'].label_outer()\n",
    "ax['v'].set(title='transpose=False')\n",
    "librosa.display.waveshow(y, ax=ax['h'], transpose=True)\n",
    "ax['h'].label_outer()\n",
    "ax['h'].set(title='transpose=True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfb78f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Number41",
   "language": "python",
   "name": "number41"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
