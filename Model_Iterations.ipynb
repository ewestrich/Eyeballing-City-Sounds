{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1090f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from tensorflow.keras import datasets\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.val_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "validation_generator = train_data_gen.flow_from_directory(\n",
    "    \n",
    "                                                    train_dir, \n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    color_mode = 'rgb',\n",
    "                                                    seed = 42,\n",
    "                                                    subset = 'validation',\n",
    "\n",
    ")\n",
    "\n",
    "test_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_generator = test_data_gen.flow_from_directory(\n",
    "\n",
    "                                                    test_dir, \n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    color_mode = 'rgb',\n",
    "                                                    seed = 42,\n",
    "                                                    shuffle = False\n",
    "\n",
    ")\n",
    "\n",
    "\n",
    "model = Sequential()models import Sequential\n",
    "\n",
    "from tensorflow.keras.layers import Dense # creates densely connected layer object\n",
    "from tensorflow.keras.layers import Flatten # takes 2D input and turns into 1D array\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D # convolution layer\n",
    "from tensorflow.keras.layers import MaxPooling2D # max pooling layer\n",
    "\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.layers import Dropout\n",
    "\n",
    "# a new layer that rescales/normalizes the activations after each layer.\n",
    "# has a weak regularization effect. also allows \n",
    "\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.layers import Activation\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2f07011",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = '/Users/eitan/Documents/Flatiron/Capstone/train_splits'\n",
    "\n",
    "test_dir = '/Users/eitan/Documents/Flatiron/Capstone/test_splits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3fde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_gen = ImageDataGenerator(rescale = 1./255, validation_split = .2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b3a6dc8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5240 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_data_gen.flow_from_directory(\n",
    "    \n",
    "                                                    train_dir, \n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    color_mode = 'rgb',\n",
    "                                                    seed = 42,\n",
    "                                                    subset = 'training',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfdec8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf9cce75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1309 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_data_gen.flow_from_directory(\n",
    "    \n",
    "                                                    train_dir, \n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    color_mode = 'rgb',\n",
    "                                                    seed = 42,\n",
    "                                                    subset = 'validation',\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18a2ee36",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a40bc35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2183 images belonging to 10 classes.\n"
     ]
    }
   ],
   "source": [
    "test_generator = test_data_gen.flow_from_directory(\n",
    "\n",
    "                                                    test_dir, \n",
    "                                                    target_size = (150, 150),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'categorical',\n",
    "                                                    color_mode = 'rgb',\n",
    "                                                    seed = 42,\n",
    "                                                    shuffle = False\n",
    "\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db193d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a659af0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3)))\n",
    "# max pool in 2x2 window\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d3eeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model2.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3), kernel_regularizer = l2(5e-4) ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "# max pool in 2x2 window\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-4) ))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-4)))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(256, activation='relu'))\n",
    "model2.add(Dropout(0.2))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(128, activation='relu'))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.25))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da206900",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "57fb4d93",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1865047285.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[40], line 12\u001b[0;36m\u001b[0m\n\u001b[0;31m    model2.add(Conv2D(64, (3, 3), activation='relu', , kernel_regularizer = l2(5e-3)))\u001b[0m\n\u001b[0m                                                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model2.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3), kernel_regularizer = l2(5e-4) ))\n",
    "\n",
    "# max pool in 2x2 window\n",
    "model2.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-4)))\n",
    "\n",
    "\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c75b3846",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "164/164 [==============================] - 41s 247ms/step - loss: 1.5636 - accuracy: 0.4523 - val_loss: 2.1088 - val_accuracy: 0.2804\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 41s 248ms/step - loss: 1.0143 - accuracy: 0.6655 - val_loss: 1.8512 - val_accuracy: 0.3858\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 0.7697 - accuracy: 0.7500 - val_loss: 1.9948 - val_accuracy: 0.3644\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 40s 246ms/step - loss: 0.5721 - accuracy: 0.8145 - val_loss: 1.9896 - val_accuracy: 0.4714\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 40s 246ms/step - loss: 0.4057 - accuracy: 0.8760 - val_loss: 2.2155 - val_accuracy: 0.4882\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 41s 249ms/step - loss: 0.3073 - accuracy: 0.9080 - val_loss: 2.2193 - val_accuracy: 0.5332\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 40s 246ms/step - loss: 0.2458 - accuracy: 0.9275 - val_loss: 3.8928 - val_accuracy: 0.4347\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 41s 246ms/step - loss: 0.1612 - accuracy: 0.9567 - val_loss: 2.1712 - val_accuracy: 0.5523\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 41s 248ms/step - loss: 0.1532 - accuracy: 0.9613 - val_loss: 2.3612 - val_accuracy: 0.5462\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 42s 254ms/step - loss: 0.1068 - accuracy: 0.9763 - val_loss: 3.8925 - val_accuracy: 0.4591\n"
     ]
    }
   ],
   "source": [
    "history_cnn = model2.fit(train_generator,\n",
    "                        validation_data = validation_generator,\n",
    "                        epochs = 10,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "85fea96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model3.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3), kernel_regularizer = l2(5e-3) ))\n",
    "\n",
    "# max pool in 2x2 window\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ffebbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "164/164 [==============================] - 41s 251ms/step - loss: 2.3766 - accuracy: 0.3393 - val_loss: 2.5682 - val_accuracy: 0.3583\n",
      "Epoch 2/10\n",
      "164/164 [==============================] - 41s 249ms/step - loss: 1.5197 - accuracy: 0.6080 - val_loss: 2.0662 - val_accuracy: 0.3965\n",
      "Epoch 3/10\n",
      "164/164 [==============================] - 40s 245ms/step - loss: 1.1144 - accuracy: 0.7168 - val_loss: 1.8853 - val_accuracy: 0.4645\n",
      "Epoch 4/10\n",
      "164/164 [==============================] - 40s 245ms/step - loss: 0.8517 - accuracy: 0.8031 - val_loss: 1.6711 - val_accuracy: 0.5141\n",
      "Epoch 5/10\n",
      "164/164 [==============================] - 41s 250ms/step - loss: 0.6760 - accuracy: 0.8468 - val_loss: 2.2010 - val_accuracy: 0.4836\n",
      "Epoch 6/10\n",
      "164/164 [==============================] - 40s 245ms/step - loss: 0.5599 - accuracy: 0.8842 - val_loss: 2.4043 - val_accuracy: 0.5332\n",
      "Epoch 7/10\n",
      "164/164 [==============================] - 41s 248ms/step - loss: 0.4591 - accuracy: 0.9073 - val_loss: 2.3417 - val_accuracy: 0.4836\n",
      "Epoch 8/10\n",
      "164/164 [==============================] - 40s 244ms/step - loss: 0.3907 - accuracy: 0.9336 - val_loss: 2.4927 - val_accuracy: 0.5279\n",
      "Epoch 9/10\n",
      "164/164 [==============================] - 40s 245ms/step - loss: 0.3340 - accuracy: 0.9496 - val_loss: 3.0739 - val_accuracy: 0.5080\n",
      "Epoch 10/10\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 0.2858 - accuracy: 0.9632 - val_loss: 4.7286 - val_accuracy: 0.4110\n"
     ]
    }
   ],
   "source": [
    "history_cnn_3 = model3.fit(train_generator,\n",
    "                        validation_data = validation_generator,\n",
    "                        epochs = 10,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c4097859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_15\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_35 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_21 (MaxPooli  (None, 74, 74, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_36 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_22 (MaxPooli  (None, 36, 36, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_37 (Conv2D)          (None, 34, 34, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_40 (Ba  (None, 34, 34, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_23 (MaxPooli  (None, 17, 17, 64)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_38 (Conv2D)          (None, 15, 15, 64)        36928     \n",
      "                                                                 \n",
      " flatten_10 (Flatten)        (None, 14400)             0         \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 64)                921664    \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1015818 (3.88 MB)\n",
      "Trainable params: 1015690 (3.87 MB)\n",
      "Non-trainable params: 128 (512.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model3.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2baa2343",
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = Sequential()\n",
    "\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model4.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3), kernel_regularizer = l2(5e-3) ))\n",
    "\n",
    "# max pool in 2x2 window\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model4.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "model4.add(MaxPooling2D((2, 2)))\n",
    "model4.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(MaxPooling2D((2, 2)))\n",
    "model4.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model4.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "07355640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 41s 249ms/step - loss: 2.4973 - accuracy: 0.2601 - val_loss: 2.6534 - val_accuracy: 0.1146\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 43s 260ms/step - loss: 1.9691 - accuracy: 0.3672 - val_loss: 2.5826 - val_accuracy: 0.1215\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 41s 249ms/step - loss: 1.7939 - accuracy: 0.4101 - val_loss: 1.8189 - val_accuracy: 0.4125\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 41s 248ms/step - loss: 1.6284 - accuracy: 0.4506 - val_loss: 2.8540 - val_accuracy: 0.2353\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 41s 247ms/step - loss: 1.5001 - accuracy: 0.4964 - val_loss: 2.1879 - val_accuracy: 0.2582\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 41s 246ms/step - loss: 1.3527 - accuracy: 0.5574 - val_loss: 1.6970 - val_accuracy: 0.3995\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 39s 240ms/step - loss: 1.2798 - accuracy: 0.5882 - val_loss: 1.7149 - val_accuracy: 0.4301\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 40s 244ms/step - loss: 1.3244 - accuracy: 0.5683 - val_loss: 3.0570 - val_accuracy: 0.2628\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 40s 245ms/step - loss: 1.2688 - accuracy: 0.5943 - val_loss: 1.7920 - val_accuracy: 0.4003\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 41s 249ms/step - loss: 1.1269 - accuracy: 0.6422 - val_loss: 1.7770 - val_accuracy: 0.4652\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 42s 253ms/step - loss: 1.1311 - accuracy: 0.6471 - val_loss: 1.8442 - val_accuracy: 0.4316\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 41s 247ms/step - loss: 1.0471 - accuracy: 0.6723 - val_loss: 1.6111 - val_accuracy: 0.4889\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 41s 247ms/step - loss: 1.0027 - accuracy: 0.6983 - val_loss: 2.6918 - val_accuracy: 0.3560\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 41s 247ms/step - loss: 0.8980 - accuracy: 0.7342 - val_loss: 2.5443 - val_accuracy: 0.3682\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 0.8629 - accuracy: 0.7376 - val_loss: 1.5939 - val_accuracy: 0.5118\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 41s 247ms/step - loss: 0.8212 - accuracy: 0.7613 - val_loss: 1.7869 - val_accuracy: 0.4652\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 41s 251ms/step - loss: 0.8003 - accuracy: 0.7668 - val_loss: 1.5818 - val_accuracy: 0.5126\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 40s 246ms/step - loss: 0.7717 - accuracy: 0.7746 - val_loss: 1.8333 - val_accuracy: 0.4683\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 42s 256ms/step - loss: 0.7508 - accuracy: 0.7824 - val_loss: 1.5938 - val_accuracy: 0.5439\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 41s 248ms/step - loss: 0.6590 - accuracy: 0.8118 - val_loss: 1.9606 - val_accuracy: 0.4882\n"
     ]
    }
   ],
   "source": [
    "history_cnn_4 = model4.fit(train_generator,\n",
    "                        validation_data = validation_generator,\n",
    "                        epochs = 20,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaef3d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6256a899",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a02708c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7731a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2c2c65",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e154f17b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = Sequential()\n",
    "\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model3.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3), kernel_regularizer = l2(5e-3) ))\n",
    "\n",
    "# max pool in 2x2 window\n",
    "model3.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "\n",
    "model3.add(BatchNormalization())\n",
    "model3.add(MaxPooling2D((2, 2)))\n",
    "model3.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3)))\n",
    "\n",
    "\n",
    "model2.add(BatchNormalization())\n",
    "model2.add(Dense(64, activation='relu'))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model2.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model3.add(Flatten())\n",
    "model3.add(Dense(64, activation='relu'))\n",
    "\n",
    "\n",
    "model3.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model3.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model4 = Sequential()\n",
    "# define 3x3 filter window sizes. Create 32 filters.\n",
    "model4.add(Conv2D(filters=32,\n",
    "                        kernel_size=(3, 3),              # changed kernel size back to 3x3\n",
    "                        activation='relu',\n",
    "                        input_shape=(150, 150, 3)) )      # took out first regularizer\n",
    "\n",
    "model4.add(BatchNormalization())\n",
    "# max pool in 2x2 window\n",
    "model4.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# define 3x3 filter window sizes. Create 64 filters.\n",
    "model4.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer = l2(5e-3) ))\n",
    "\n",
    "                                         # removed a layer\n",
    "           \n",
    "model4.add(BatchNormalization())\n",
    "\n",
    "# transition to dense fully-connected part of network\n",
    "model4.add(Flatten())\n",
    "model4.add(Dense(128, activation='relu'))\n",
    "model4.add(Dropout(0.2))\n",
    "\n",
    "                                # removed a layer\n",
    "           \n",
    "model4.add(BatchNormalization())\n",
    "model4.add(Dense(64, activation='relu'))\n",
    "model4.add(Dropout(0.25))\n",
    "\n",
    "model4.add(Dense(10, activation='softmax'))\n",
    "\n",
    "model4.compile(optimizer='adam', loss='categorical_crossentropy',  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad4264ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_19 (Conv2D)          (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " batch_normalization_25 (Ba  (None, 148, 148, 32)      128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPooli  (None, 74, 74, 32)        0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_20 (Conv2D)          (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_26 (Ba  (None, 72, 72, 64)        256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " flatten_5 (Flatten)         (None, 331776)            0         \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 128)               42467456  \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 128)               0         \n",
      "                                                                 \n",
      " batch_normalization_27 (Ba  (None, 128)               512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 64)                8256      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 10)                650       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 42496650 (162.11 MB)\n",
      "Trainable params: 42496202 (162.11 MB)\n",
      "Non-trainable params: 448 (1.75 KB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model4.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "812a14d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "164/164 [==============================] - 64s 383ms/step - loss: 2.2400 - accuracy: 0.2334 - val_loss: 2.3775 - val_accuracy: 0.1474\n",
      "Epoch 2/20\n",
      "164/164 [==============================] - 59s 356ms/step - loss: 1.9374 - accuracy: 0.3342 - val_loss: 2.0380 - val_accuracy: 0.2689\n",
      "Epoch 3/20\n",
      "164/164 [==============================] - 54s 328ms/step - loss: 1.7708 - accuracy: 0.3981 - val_loss: 2.3269 - val_accuracy: 0.1971\n",
      "Epoch 4/20\n",
      "164/164 [==============================] - 54s 331ms/step - loss: 1.6246 - accuracy: 0.4544 - val_loss: 2.2130 - val_accuracy: 0.2865\n",
      "Epoch 5/20\n",
      "164/164 [==============================] - 53s 324ms/step - loss: 1.5632 - accuracy: 0.4718 - val_loss: 2.2835 - val_accuracy: 0.3201\n",
      "Epoch 6/20\n",
      "164/164 [==============================] - 53s 319ms/step - loss: 1.4667 - accuracy: 0.5124 - val_loss: 2.3414 - val_accuracy: 0.3224\n",
      "Epoch 7/20\n",
      "164/164 [==============================] - 54s 326ms/step - loss: 1.3821 - accuracy: 0.5427 - val_loss: 195.3152 - val_accuracy: 0.1536\n",
      "Epoch 8/20\n",
      "164/164 [==============================] - 53s 325ms/step - loss: 1.5527 - accuracy: 0.4794 - val_loss: 797.6280 - val_accuracy: 0.1963\n",
      "Epoch 9/20\n",
      "164/164 [==============================] - 53s 323ms/step - loss: 1.4992 - accuracy: 0.5029 - val_loss: 3.7925 - val_accuracy: 0.2315\n",
      "Epoch 10/20\n",
      "164/164 [==============================] - 53s 323ms/step - loss: 1.2654 - accuracy: 0.5906 - val_loss: 501.6740 - val_accuracy: 0.0947\n",
      "Epoch 11/20\n",
      "164/164 [==============================] - 53s 324ms/step - loss: 1.0473 - accuracy: 0.6723 - val_loss: 4.0522 - val_accuracy: 0.3705\n",
      "Epoch 12/20\n",
      "164/164 [==============================] - 55s 332ms/step - loss: 1.3406 - accuracy: 0.5800 - val_loss: 1391.7671 - val_accuracy: 0.1062\n",
      "Epoch 13/20\n",
      "164/164 [==============================] - 56s 341ms/step - loss: 1.2092 - accuracy: 0.6202 - val_loss: 5.4186 - val_accuracy: 0.3239\n",
      "Epoch 14/20\n",
      "164/164 [==============================] - 54s 330ms/step - loss: 1.0804 - accuracy: 0.6742 - val_loss: 810.9518 - val_accuracy: 0.0351\n",
      "Epoch 15/20\n",
      "164/164 [==============================] - 54s 326ms/step - loss: 1.0953 - accuracy: 0.6620 - val_loss: 14.9943 - val_accuracy: 0.3147\n",
      "Epoch 16/20\n",
      "164/164 [==============================] - 54s 331ms/step - loss: 1.3731 - accuracy: 0.5653 - val_loss: 2.7523 - val_accuracy: 0.3293\n",
      "Epoch 17/20\n",
      "164/164 [==============================] - 53s 324ms/step - loss: 1.1670 - accuracy: 0.6303 - val_loss: 2.6126 - val_accuracy: 0.2964\n",
      "Epoch 18/20\n",
      "164/164 [==============================] - 55s 335ms/step - loss: 1.1203 - accuracy: 0.6563 - val_loss: 2.0550 - val_accuracy: 0.4072\n",
      "Epoch 19/20\n",
      "164/164 [==============================] - 54s 329ms/step - loss: 0.9346 - accuracy: 0.7240 - val_loss: 2.1798 - val_accuracy: 0.3797\n",
      "Epoch 20/20\n",
      "164/164 [==============================] - 59s 356ms/step - loss: 0.8262 - accuracy: 0.7613 - val_loss: 3.2120 - val_accuracy: 0.4423\n"
     ]
    }
   ],
   "source": [
    "history_cnn_4 = model4.fit(train_generator,\n",
    "                        validation_data = validation_generator,\n",
    "                        epochs = 20,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406fd0b0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python Number41",
   "language": "python",
   "name": "number41"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
